## üñ• Atividades Em Grupo

Reinforcement Learning: https://github.com/klaytoncastro/idp-machinelearning/tree/main/reinforcement  
RNA (Redes Neurais Artificiais): https://github.com/klaytoncastro/idp-machinelearning/tree/main/rna  

## üïπÔ∏è Reinforcement Learning (Minimax)

<details>
Este projeto implementa o cl√°ssico jogo da velha utilizando o algoritmo **Minimax** para criar uma intelig√™ncia artificial (IA) capaz de jogar contra um humano. A aplica√ß√£o foi desenvolvida como parte do trabalho do **Grupo 2** no estudo de algoritmos de busca em jogos.

---

## üìö Descri√ß√£o do Projeto

A aplica√ß√£o apresenta:
1. **Tabuleiro do Jogo da Velha** em um layout baseado em texto.
2. Um sistema para o jogador humano escolher entre os s√≠mbolos `X` e `O`.
3. O uso do algoritmo **Minimax** para calcular o melhor movimento para a IA.
4. Uma mec√¢nica de sorteio para definir quem come√ßa o jogo.

O objetivo principal √© demonstrar o funcionamento do **Minimax**, um algoritmo amplamente utilizado em jogos de tabuleiro para determinar a jogada √≥tima.

---

## üîß Estrutura do C√≥digo

### Fun√ß√µes Principais
- **`check_winner(board)`**: Verifica se h√° um vencedor no jogo.
- **`is_board_full(board)`**: Determina se o tabuleiro est√° completamente preenchido (empate).
- **`minimax(board, is_maximizing, player)`**: Implementa√ß√£o do algoritmo Minimax para explorar todas as possibilidades de jogadas e escolher a melhor.
- **`best_move(board, player)`**: Calcula o melhor movimento da IA com base no Minimax.
- **`print_board(board)`**: Exibe o estado atual do tabuleiro.
- **`play_game()`**: Controla o fluxo principal do jogo, alternando entre o humano e a IA.
- **`human_turn(board, player)`**: Permite que o humano fa√ßa uma jogada.
- **`ai_turn(board, ai, player)`**: Executa a jogada da IA.
- **`check_game_over(board)`**: Verifica se o jogo terminou (vit√≥ria ou empate).

---

## üß† Como o Algoritmo Minimax Funciona

O **Minimax** avalia todas as jogadas poss√≠veis no tabuleiro e atribui um valor a cada cen√°rio:
- **Vit√≥ria do oponente**: Retorna `-1`.
- **Vit√≥ria da IA**: Retorna `1`.
- **Empate**: Retorna `0`.

A IA maximiza suas chances de vencer enquanto minimiza as chances do oponente. Este processo envolve chamadas recursivas para avaliar todos os cen√°rios poss√≠veis at√© o final do jogo.

### Exemplo de Execu√ß√£o do Minimax
1. O tabuleiro atual √© avaliado.
2. A IA simula todas as jogadas poss√≠veis.
3. Cada resultado √© ponderado para encontrar a jogada √≥tima.

---

## üöÄ Grupo do Trabalho

- Mariana
- F√°bio
- Sara
- Arthur
- Felipe Barroso **(Eu)**
- Igor
- Eduardo
- Pedro Calil

</details>

## üß† RNA (Redes Neurais Artificiais)

<details>

# Projeto de Redes Neurais Artificiais (RNA)

Este projeto aborda a implementa√ß√£o e o uso de Redes Neurais Artificiais (RNA) para resolver problemas espec√≠ficos utilizando frameworks como **TensorFlow** ou **PyTorch**. O trabalho foi desenvolvido como parte das atividades pr√°ticas do curso de Machine Learning.

## Estrutura do Reposit√≥rio

- **`Grupo1_RNA.ipynb`**: Notebook principal contendo o c√≥digo para implementa√ß√£o das Redes Neurais Artificiais.
- **`dataset.csv`** (exemplo): Conjunto de dados utilizado para treinar e avaliar as RNAs. 

## Objetivo

O objetivo principal deste projeto foi:
- Implementar Redes Neurais Artificiais para um problema espec√≠fico.
- Treinar e avaliar a performance do modelo utilizando m√©tricas apropriadas.
- Explorar diferentes arquiteturas de redes neurais para observar o impacto em sua performance.

## Etapas do Projeto

### 1. Carregamento e Prepara√ß√£o dos Dados
- **Leitura dos Dados**:
  - Os dados foram carregados de um arquivo CSV e analisados.
- **Pr√©-processamento**:
  - Normaliza√ß√£o dos dados para garantir que todas as vari√°veis estivessem na mesma escala.
  - Divis√£o do dataset em conjuntos de treino e teste.

### 2. Implementa√ß√£o do Modelo RNA
- **Biblioteca Utilizada**: TensorFlow ou PyTorch.
- **Arquitetura da Rede**:
  - Camadas densamente conectadas (Dense Layers).
  - Fun√ß√µes de ativa√ß√£o utilizadas: `ReLU`, `Sigmoid`, ou outras dependendo do problema.
  - Otimizador: Adam ou SGD (Stochastic Gradient Descent).
  - Fun√ß√£o de perda: CrossEntropy (para classifica√ß√£o) ou MSE (para regress√£o).

### 3. Treinamento e Avalia√ß√£o
- **Treinamento**:
  - Configurado para rodar por um n√∫mero definido de √©pocas.
  - Monitoramento de m√©tricas como acur√°cia, perda (loss) e valida√ß√£o.
- **Avalia√ß√£o**:
  - M√©tricas calculadas no conjunto de teste, como Acur√°cia, Precision, Recall, F1-Score.
  - Gr√°ficos de perda e acur√°cia foram gerados para avaliar o desempenho.

### 4. Resultados e An√°lise
- **Desempenho da Rede**:
  - A rede neural conseguiu aprender padr√µes significativos nos dados.
  - Resultados foram comparados com abordagens tradicionais (como regress√£o log√≠stica ou √°rvores de decis√£o).
- **Visualiza√ß√µes**:
  - Gr√°ficos de converg√™ncia (loss/accuracy).
  - Compara√ß√£o entre valores reais e previstos.

### 5. Conclus√µes
- **Conclus√µes Gerais**:
  - O modelo apresentou bom desempenho para a tarefa proposta.
  - Redes neurais foram capazes de capturar padr√µes complexos que algoritmos tradicionais n√£o conseguiram.
- **Limita√ß√µes**:
  - O tempo de treinamento foi elevado devido ao tamanho do dataset e √† complexidade da rede.
  - Testes adicionais poderiam ser realizados com arquiteturas mais avan√ßadas, como Redes Convolucionais (CNNs) ou Redes Recorrentes (RNNs).

## Ferramentas Utilizadas

- **Linguagens/Bibliotecas**:
  - Python
  - TensorFlow ou PyTorch
  - pandas, numpy
  - matplotlib, seaborn
- **Ambiente de Desenvolvimento**:
  - Jupyter Notebook
 
## Grupo
- F√°bio
- Sara
- Arthur
- Felipe Barroso
- Lucas Narita

</details>

---

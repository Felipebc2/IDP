
---

## üñ• Atividades Individuais

**Air Quality Dataset:**
https://github.com/klaytoncastro/idp-machinelearning/tree/main/airquality

**Bank Dataset:**
https://github.com/klaytoncastro/idp-machinelearning/tree/main/bank

**California Dataset:**
https://github.com/klaytoncastro/idp-machinelearning/tree/main/california

**Mall Customers Dataset:**
https://github.com/klaytoncastro/idp-machinelearning/tree/main/clustering

**Iris Dataset:**
https://github.com/klaytoncastro/idp-machinelearning/tree/main/iris

**Sentiment Analysis**
https://github.com/klaytoncastro/idp-machinelearning/tree/main/nlp

---

## üå™Ô∏è Air Quality Dataset

<details>

# An√°lise do Air Quality Dataset

Este reposit√≥rio cont√©m um notebook em Python com a an√°lise explorat√≥ria de dados e aplica√ß√£o de t√©cnicas de Machine Learning no **Air Quality Dataset**, como parte das atividades pr√°ticas de aprendizado.

## Estrutura do Reposit√≥rio

- **`Airquality_Felipe_Barroso.ipynb`**: Notebook principal contendo todas as etapas do projeto.
- **`AirQualityUCI.csv`**: Arquivo com os dados originais utilizados no projeto.

## Objetivo

O objetivo principal deste projeto foi analisar a qualidade do ar com base em medi√ß√µes de gases e vari√°veis clim√°ticas, al√©m de criar modelos preditivos para estimar concentra√ß√µes de CO no ar.

## Etapas Realizadas

1. **Carregamento e Limpeza de Dados**
   - Importa√ß√£o do dataset em formato CSV.
   - Tratamento de valores ausentes preenchendo com a mediana.
   - Remo√ß√£o de colunas irrelevantes ou n√£o num√©ricas.

2. **An√°lise Explorat√≥ria de Dados (EDA)**
   - Gera√ß√£o de estat√≠sticas descritivas.
   - Visualiza√ß√µes gr√°ficas das distribui√ß√µes das vari√°veis.
   - Matriz de correla√ß√£o para identificar rela√ß√µes entre vari√°veis.

3. **Pr√©-processamento**
   - Sele√ß√£o de vari√°veis independentes (features) e dependente (target).
   - Divis√£o do dataset em conjuntos de treino e teste.

4. **Modelagem de Machine Learning**
   - Treinamento de um modelo de Random Forest para prever concentra√ß√µes de CO.
   - Avalia√ß√£o do modelo com m√©tricas:
     - Mean Squared Error (MSE)
     - R-squared (R¬≤)

5. **Resultados**
   - Compara√ß√£o entre os valores reais e previstos para avaliar a efic√°cia do modelo.

6. **Conclus√µes**
   - O modelo conseguiu capturar padr√µes relevantes no dataset, apresentando um desempenho satisfat√≥rio para predi√ß√£o de CO.

## Ferramentas Utilizadas

- **Linguagem**: Python
- **Bibliotecas**:
  - `pandas`
  - `numpy`
  - `matplotlib`
  - `seaborn`
  - `scikit-learn`

## Observa√ß√µes

- Certifique-se de que o arquivo `AirQualityUCI.csv` esteja no mesmo diret√≥rio do notebook ao execut√°-lo.

</details>

---

## üè¶ Bank Dataset

<details>

# An√°lise do Bank Dataset

Este reposit√≥rio cont√©m um notebook em Python com a an√°lise explorat√≥ria de dados e aplica√ß√£o de t√©cnicas de Machine Learning no **Bank Dataset**, parte das atividades pr√°ticas do curso de Machine Learning.

## Estrutura do Reposit√≥rio

- **`Bank_Dataset_Felipe_Barroso.ipynb`**: Notebook principal contendo todas as etapas do projeto.
- **`Bank_Data.csv`**: Arquivo com os dados originais utilizados no projeto.

## Objetivo

O objetivo principal deste projeto foi analisar os dados de uma campanha de marketing de uma institui√ß√£o banc√°ria e criar modelos preditivos para estimar a probabilidade de um cliente aceitar um produto banc√°rio (como um dep√≥sito a prazo fixo).

## Etapas Realizadas

1. **Carregamento dos Dados**
   - Importa√ß√£o do arquivo `Bank_Data.csv` para o ambiente de trabalho.
   - Inspe√ß√£o inicial dos dados para compreender suas vari√°veis e estrutura.

2. **An√°lise Explorat√≥ria de Dados (EDA)**
   - Estat√≠sticas descritivas das vari√°veis.
   - Visualiza√ß√µes gr√°ficas para identificar padr√µes e rela√ß√µes entre os dados.
   - Tratamento de dados ausentes e outliers.

3. **Pr√©-processamento**
   - Convers√£o de vari√°veis categ√≥ricas para representa√ß√µes num√©ricas.
   - Normaliza√ß√£o de vari√°veis para uso em modelos de aprendizado de m√°quina.
   - Divis√£o dos dados em conjuntos de treinamento e teste.

4. **Modelagem**
   - Treinamento de diferentes algoritmos de classifica√ß√£o:
     - Regress√£o Log√≠stica
     - √Årvore de Decis√£o
     - Random Forest
   - Avalia√ß√£o de desempenho dos modelos utilizando m√©tricas como:
     - Acur√°cia
     - Precis√£o
     - Recall
     - F1-score

5. **Resultados**
   - Compara√ß√£o entre os modelos com base nas m√©tricas de avalia√ß√£o.
   - Identifica√ß√£o do melhor modelo para o problema proposto.

6. **Conclus√µes**
   - Insights gerados a partir dos dados.
   - Discuss√£o sobre a aplicabilidade do modelo no mundo real.

## Ferramentas Utilizadas

- Python (bibliotecas: pandas, numpy, matplotlib, seaborn, scikit-learn)
- Jupyter Notebook

## Observa√ß√µes

- Certifique-se de que o arquivo `Bank_Data.csv` esteja no mesmo diret√≥rio do notebook.

</details>

---

## ‚õ±Ô∏è California Dataset

<details>

# An√°lise do California Housing Dataset

Este reposit√≥rio cont√©m um notebook em Python com a an√°lise explorat√≥ria, pr√©-processamento e aplica√ß√£o de modelos de machine learning no **California Housing Dataset**.

## Estrutura do Reposit√≥rio

- **`california_housing_analysis.ipynb`**: Notebook contendo a an√°lise completa e modelagem dos dados.
- **`california_housing.csv`**: Arquivo com os dados originais utilizados no projeto.

## Objetivo

O objetivo principal deste projeto foi prever o valor m√©dio de casas em diferentes regi√µes da Calif√≥rnia, utilizando vari√°veis como idade m√©dia das casas, n√∫mero m√©dio de quartos, ocupa√ß√£o m√©dia, latitude, longitude, entre outras.

## Etapas do Projeto

### 1. An√°lise Explorat√≥ria de Dados (EDA)
- **Distribui√ß√£o das Vari√°veis**: Analisamos as distribui√ß√µes das vari√°veis para identificar outliers e entender caracter√≠sticas gerais do conjunto de dados.
- **Correla√ß√£o**: Exploramos as correla√ß√µes entre as vari√°veis preditoras e a vari√°vel alvo (`MedHouseVal`).
- **Gr√°ficos**:
  - Histogramas para distribui√ß√£o de vari√°veis.
  - Matriz de correla√ß√£o para identificar rela√ß√µes entre as vari√°veis.

### 2. Pr√©-processamento de Dados
- **Tratamento de Valores Ausentes**: Identifica√ß√£o e tratamento de valores ausentes (se aplic√°vel).
- **Normaliza√ß√£o**: Vari√°veis foram normalizadas com `StandardScaler` para garantir que todas as vari√°veis estivessem na mesma escala.
- **Divis√£o dos Dados**: O dataset foi dividido em conjuntos de treino (80%) e teste (20%) para valida√ß√£o dos modelos.

### 3. Modelagem
Foram aplicados e avaliados diferentes algoritmos de regress√£o para prever o valor m√©dio das casas:
- **Regress√£o Linear**: Modelo b√°sico para estabelecer uma linha de base.
- **√Årvore de Decis√£o**: Modelo n√£o linear para capturar intera√ß√µes complexas.
- **Random Forest**: Modelo de ensemble para melhorar a performance e reduzir overfitting.
- **SVR (Support Vector Regressor)**: Modelo de regress√£o baseado no algoritmo SVM.
- **Gradient Boosting Machines**: Implementa√ß√£o com `GradientBoostingRegressor`.

### 4. Avalia√ß√£o e Interpreta√ß√£o
- **M√©tricas de Avalia√ß√£o**:
  - **MAE (Mean Absolute Error)**: Erro m√©dio absoluto.
  - **MSE (Mean Squared Error)**: Erro quadr√°tico m√©dio.
  - **R¬≤ (Coeficiente de Determina√ß√£o)**: Mede a propor√ß√£o da vari√¢ncia explicada pelo modelo.
- **Gr√°ficos de Valores Reais x Preditos**:
  - Para cada modelo, geramos gr√°ficos de dispers√£o comparando os valores reais e os previstos.

## Ferramentas Utilizadas

- **Linguagem**: Python
- **Bibliotecas**:
  - `pandas`
  - `numpy`
  - `matplotlib`
  - `seaborn`
  - `scikit-learn`

## Resultados

- **Modelos Avaliados**:
  - Regress√£o Linear apresentou bom desempenho como modelo inicial.
  - Random Forest e Gradient Boosting Machines se destacaram pelo melhor equil√≠brio entre bias e vari√¢ncia.
- **Insights**:
  - Vari√°veis como `MedInc` (Renda M√©dia) mostraram forte correla√ß√£o com o valor m√©dio das casas.
  - Modelos ensemble como Random Forest e Gradient Boosting s√£o mais adequados para capturar padr√µes complexos.

</details>

---

## üè¢ Mall Customers Dataset

<details>


</details>

---

## üëÅÔ∏è Iris Dataset

<details>


</details>

---

## üíï Sentiment Analysis

<details>


</details>

---
